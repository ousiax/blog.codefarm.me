<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Bing WebMaster -->
  <meta name="msvalidate.01" content="AB2FFF876C37F59D9121882CC8395DE5" />

  <title>Learning Notes: Fundamentals of Data Engineering</title>
  <meta name="description" content="">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://blog.codefarm.me/2025/05/31/learning-notes-fundamentals-of-data-engineering/">
  <link rel="alternate" type="application/rss+xml" title="CODE FARM" href="https://blog.codefarm.me/feed.xml">

  <!--<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" />-->

  <!-- https://cdn.jsdelivr.net/gh/lurongkai/anti-baidu/js/anti-baidu-latest.min.js -->
<script type="text/javascript" src="/js/anti-baidu.min.js" charset="UTF-8"></script>

  
<!-- Google Analytics Website tracking -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-83971182-1', 'auto');
  ga('send', 'pageview');

</script>


  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SN88FJ18E5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SN88FJ18E5');
</script>



</head>


  <body>

    <header class="site-header">

  <div class="wrapper">
    <h2 class="site-title">
      <a class="site-title" href="/">CODE FARM</a>
    </h2>

     <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
        <div class="trigger">
            <ul>
                <li><a href="/">home</a>
                <li><a href="/category">category</a>
                <li><a href="/tag">tag</a>
                <li><a href="/archive">archive</a>
                <li><a href="/about">about</a>
                <li><a href="https://resume.github.io/?ousiax" target="_blank">R&eacute;sum&eacute;</a>
            </ul>
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Learning Notes: Fundamentals of Data Engineering</h1>
    
    
    <p class="post-meta"><time datetime="2025-05-31T08:34:33+08:00" itemprop="datePublished">May 31, 2025</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <div class="paragraph">
<p><em>Data engineering</em> is the development, implementation, and maintenance of systems and processes that take in raw data and produce high-quality, consistent information that supports downstream use cases, such as analysis and machine learning. Data engineering is the intersection of security, data management, DataOps, data architecture, orchestration, and software engineering. A <em>data engineer</em> manages the data engineering lifecycle, beginning with getting data from source systems and ending with serving data for use cases, such as analysis or machine learning.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/assets/learning-notes-fundamentals-of-data-engineering/data-engineering-lifecycle.png" alt="Data engineering lifecycle" width="55%" height="55%">
</div>
</div>
<div class="paragraph">
<p><em>ETL</em> (extract, transform, load) is the traditional data warehouse approach where the extract phase pulls data from source systems, the transform phase cleans and standardizes data while organizing and imposing business logic in a highly modeled form, and the load phase pushes the transformed data into the data warehouse target database system, and the processes are typically handled by external systems and work hand-in-hand with specific business structures and teams.</p>
</div>
<div class="paragraph">
<p><em>ELT</em> (extract, load, transform) is a variation where data is moved more directly from production systems into a staging area in the data warehouse in raw form, and transformations are handled directly within the data warehouse itself rather than using external systems, that takes advantage of the massive computational power of cloud data warehouses and data processing tools, with data processed in batches and transformed output written into tables and views for analytics.</p>
</div>
<div class="paragraph">
<p>A <em>data warehouse</em> is a central data hub designed for reporting and analysis, characterized as a subject-oriented, integrated, nonvolatile, and time-variant collection of data that supports management decisions.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Data warehouses separate online analytical processing (OLAP) from production databases and centralizes data through ETL (extract, transform, load) or ELT (extract, load, transform) processes, organizing data into highly formatted structures optimized for analytics.</p>
</li>
<li>
<p>Data warehouses traditionally required significant enterprise budgets but have become more accessible through cloud models.</p>
</li>
<li>
<p>A data mart is a refined subset of a data warehouse specifically designed to serve the analytics and reporting needs of a single suborganization, department, or line of business.</p>
</li>
<li>
<p>Data marts exist to make data more accessible to analysts and provide an additional transformation stage beyond initial ETL/ELT pipelines, improving performance for complex queries by pre-joining and aggregating data.</p>
</li>
<li>
<p>Cloud data warehouses represent a significant evolution from on-premises architectures, pioneered by Amazon Redshift and popularized by Google BigQuery and Snowflake, which offer pay-as-you-go scalability, separate compute from storage using object storage for virtually limitless capacity, and can process petabytes of data in single queries.</p>
</li>
<li>
<p>Cloud data warehouses have expanded MPP capabilities to cover big data use cases that previously required Hadoop clusters, blurring the line between traditional data warehouses and data lakes while evolving into broader data platforms with enhanced capabilities.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>A <em>data lake</em> is a central repository that stores all data—structured, semi-structured, and unstructured—in its raw format with virtually limitless capacity, emerging during the big data era as an alternative to structured data warehouses that promised democratized data access and flexible processing using technologies like Spark, but first-generation data lake 1.0 became known as a "data swamp" due to lack of schema management, data cataloging, and discovery tools, while being write-only and creating compliance issues with regulations like GDPR, CCPA etc.</p>
</div>
<div class="paragraph">
<p>A <em>data lakehouse</em> represents a convergence between data lakes and data warehouses, incorporating the controls, data management, and data structures found in data warehouses while still housing data in object storage and supporting various query and transformation engines, with ACID transaction support that addresses the limitations of first-generation data lakes by providing proper data management capabilities instead of the original write-only approach.</p>
</div>
<div class="paragraph">
<p><em>Lambda architecture</em> is a data processing architecture that handles both batch and streaming data through three independent systems: a batch layer that processes historical data in systems like data warehouses, a speed layer that processes real-time data with low latency using NoSQL databases, and a serving layer that combines results from both layers, though it faces challenges with managing multiple codebases and reconciling data between systems.</p>
</div>
<div class="paragraph">
<p><em>Kappa architecture</em> is an alternative to Lambda that uses a stream-processing platform as the backbone for all data handling—ingestion, storage, and serving—enabling both real-time and batch processing on the same data by reading live event streams and replaying large chunks for batch processing, though it hasn&#8217;t seen widespread adoption due to streaming complexity and cost compared to traditional batch processing.</p>
</div>
<div class="paragraph">
<p>The <em>Dataflow model</em>, developed by Google and implemented through Apache Beam, addresses the challenge of unifying batch and streaming data by viewing all data as events where aggregation is performed over various windows, treating real-time streams as unbounded data and batches as bounded event streams, enabling both processing types to happen in the same system using nearly identical code through the philosophy of "batch as a special case of streaming," which has been adopted by frameworks like Flink and Spark.</p>
</div>
<div class="paragraph">
<p>IoT devices are physical hardware that sense their environment and collect/transmit data, connected through IoT gateways that serve as hubs for data retention and internet routing, with ingestion flowing into event architectures that vary from real-time streaming to batch uploads depending on connectivity, storage requirements ranging from batch object storage for remote sensors to message queues for real-time responses, and serving patterns spanning from batch reports to real-time anomaly detection with reverse ETL patterns where analyzed sensor data is sent back to reconfigure and optimize manufacturing equipment.</p>
</div>
<div class="paragraph">
<p>An Online Transactional Processing (OLTP) data system is designed as an application database to store the state of an application, typically supporting atomicity, consistency, isolation, and durability as part of ACID characteristics, but not ideal for large-scale analytics or bulk queries.</p>
</div>
<div class="paragraph">
<p>In contrast, an online analytical processing (OLAP) system is designed for large-scale, interactive analytics queries, but making it inefficient for single record lookups but enabling its use as a data source for machine learning models or reverse ETL workflows, while the online part implies the system constantly listens for incoming queries.</p>
</div>
<div class="paragraph">
<p>A message is a discrete piece of raw data communicated between systems, which is typically removed from a queue once it&#8217;s delivered and consumed, while a stream is an append-only, ordered log of event records that are persisted over a longer duration to allow for complex analysis of what happened over many events.</p>
</div>
<div class="paragraph">
<p>While time is an essential consideration for all data ingestion, it becomes that much more critical and subtle in the context of streaming, where event time is when an event is generated at the source; ingestion time is when it enters a storage system like a message queue, cache, memory, object storage, or a database; process time is when it undergoes transformation; and processing time measures how long that transformation took, measured in seconds, minutes, hours, etc.</p>
</div>
<div class="paragraph">
<p>A Relational Database Management System (RDBMS) stores data in tables of relations (rows) with fields (columns), typically indexed by a primary key and supporting foreign keys for joins, and is popular, ACID compliant, and ideal for storing rapidly changing application states, often employing normalization to prevent data duplication.</p>
</div>
<div class="paragraph">
<p>NoSQL, or not only SQL, databases, such as key-value, document, wide-column, graph, search, and time series, are alternatives to relational systems, offering improved performance, scalability, and schema flexibility by abandoning traditional RDBMS constraints like strong consistency, joins, or fixed schemas.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A key-value database is a nonrelational database that uniquely identifies and retrieves records using a key, similar to a hash map but more scalable, offering diverse performance characteristics for use cases ranging from high-speed, temporary caching to durable persistence for massive event state changes.</p>
</li>
<li>
<p>A document store, a specialized key-value database, organizes nested objects (documents, often JSON-like) into collections for key-based retrieval; while offering schema flexibility, it is typically not ACID compliant and lacks joins, promoting denormalization, and is often eventually consistent.</p>
</li>
<li>
<p>A wide-column database is optimized for massive data storage, high transaction rates, and low latency, scaling to petabytes and millions of requests per second, making them popular in various industries; however, they only support rapid scans with a single row key index, necessitating data extraction to secondary analytics systems for complex queries. Note that wide-column refers to the database&#8217;s architecture, allowing flexible and sparse columns per row, which is distinct from a wide table, a denormalized data modeling concept with many columns.</p>
</li>
<li>
<p>Graph databases explicitly store data with a mathematical graph structure (nodes and edges), making them ideal for analyzing connectivity and complex traversals between elements, unlike other databases that struggle with such queries; they utilize specialized query languages and present unique challenges for data engineers in terms of data mapping and analytics tool adoption.</p>
</li>
<li>
<p>A search database is a nonrelational database optimized for fast search and retrieval of complex and simple semantic and structural data, primarily used for text search (exact, fuzzy, or semantic matching) and log analysis (anomaly detection, real-time monitoring, security, and operational analytics), often leveraging indexes for speed.</p>
</li>
<li>
<p>A time-series database is optimized for retrieving and statistically processing time-ordered data, handling high-velocity, often write-heavy workloads (including regularly generated measurement data and irregularly created event-based data) by utilizing memory buffering for fast writes and reads; its timestamp-ordered schema makes it suitable for operational analytics, though generally not for BI due to a typical lack of joins.</p>
</li>
</ul>
</div>
    
<style>
  .utterances {
      max-width: 100%;
  }
</style>
<script src="https://utteranc.es/client.js"
        repo="ousiax/utterances"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>


  </div>

  <ul class="post-navigation">
    <li>
      
      <a href="/2025/03/25/hands-on-large-language-models/">&laquo; Hands-On Large Language Models</a>
      
    </li>
    <li>
      
    </li>
  </ul>
</article>

      </div>
    </div>

    <footer class="site-footer">
  <div class="license">
    <span>Article licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></span>
  </div>
  
  <details open>
    <summary>Extral Links</summary>
    <div>
      
      <a href="https://jekyllrb.com/">Jekyll</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="https://shopify.github.io/">Liquid</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="https://docs.asciidoctor.org/">Asciidoctor</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="https://github.com/qqbuby/">GitHub</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="/feed.xml">RSS</a>
      
      
    </div>
  </details>
  
</footer>


<!-- https://github.com/bryanbraun/anchorjs -->
<script src="/js/anchor.min.js"></script>
<script>
  anchors.add();
  anchors.remove(".site-title");
</script>




  </body>

</html>
